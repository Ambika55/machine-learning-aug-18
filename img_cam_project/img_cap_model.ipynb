{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image, sequence\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector, Merge\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 2)\n"
     ]
    }
   ],
   "source": [
    "pd_dataset = pd.read_csv(\"./Flickr8k_text/flickr_8k_train_dataset.txt\", delimiter='\\t')\n",
    "ds = pd_dataset.values\n",
    "print ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for ix in range(ds.shape[0]):\n",
    "    sentences.append(ds[ix, 1])\n",
    "    \n",
    "print len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [i.split() for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "for i in words:\n",
    "    unique.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8253\n"
     ]
    }
   ],
   "source": [
    "unique = list(set(unique))\n",
    "print len(unique)\n",
    "\n",
    "vocab_size = len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization\n",
    "word_2_indices = {val:index for index, val in enumerate(unique)}\n",
    "indices_2_word = {index:val for index, val in enumerate(unique)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_indices['UNK'] = 0\n",
    "word_2_indices['raining'] = 8253\n",
    "\n",
    "indices_2_word[0] = 'UNK'\n",
    "indices_2_word[8253] = 'raining'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4011\n",
      "<start>\n",
      "8051\n",
      "<end>\n"
     ]
    }
   ],
   "source": [
    "print word_2_indices['<start>']\n",
    "print indices_2_word[4011]\n",
    "print word_2_indices['<end>']\n",
    "print indices_2_word[8051]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8254\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_2_indices.keys())\n",
    "print vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25493, 40)\n",
      "(25493, 8254)\n"
     ]
    }
   ],
   "source": [
    "captions = np.load(\"./captions.npy\")\n",
    "next_words = np.load(\"./next_words.npy\")\n",
    "\n",
    "print captions.shape\n",
    "print next_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25493, 2048)\n"
     ]
    }
   ],
   "source": [
    "images = np.load(\"./images.npy\")\n",
    "\n",
    "print images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25493,)\n"
     ]
    }
   ],
   "source": [
    "image = np.load(\"./image_names.npy\")\n",
    "        \n",
    "print image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "max_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 40, 128)           0         \n",
      "=================================================================\n",
      "Total params: 262,272\n",
      "Trainable params: 262,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_model = Sequential()\n",
    "\n",
    "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
    "image_model.add(RepeatVector(max_len))\n",
    "\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 40, 128)           1056512   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 40, 256)           394240    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 40, 128)           32896     \n",
      "=================================================================\n",
      "Total params: 1,483,648\n",
      "Trainable params: 1,483,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "language_model = Sequential()\n",
    "\n",
    "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))\n",
    "language_model.add(LSTM(256, return_sequences=True))\n",
    "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
    "\n",
    "language_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_9 (Merge)              (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 40, 128)           197120    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1024)              2625536   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8254)              8460350   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8254)              0         \n",
      "=================================================================\n",
      "Total params: 13,028,926\n",
      "Trainable params: 13,028,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Merge([image_model, language_model], mode='concat', concat_axis=-1))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=False)))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25493/25493 [==============================] - 221s 9ms/step - loss: 7.5953 - acc: 0.0677\n",
      "Epoch 2/20\n",
      "25493/25493 [==============================] - 217s 9ms/step - loss: 7.2610 - acc: 0.0718\n",
      "Epoch 3/20\n",
      "25493/25493 [==============================] - 218s 9ms/step - loss: 7.2978 - acc: 0.0712\n",
      "Epoch 4/20\n",
      "25493/25493 [==============================] - 217s 9ms/step - loss: 7.3173 - acc: 0.0765\n",
      "Epoch 5/20\n",
      " 3584/25493 [===>..........................] - ETA: 3:06 - loss: 7.1117 - acc: 0.0784"
     ]
    }
   ],
   "source": [
    "hist = model.fit([images, captions], next_words, batch_size=512, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
